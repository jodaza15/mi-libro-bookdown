[["modelado.html", "3 MODELADO 3.1 Modelo de Holt Winters 3.2 EXpanding windows Holt winter 3.3 Metodología Box-Jenkins 3.4 Modelo Arima 3.5 Expanding window Arima 3.6 Regresión de una serie de tiempo y Algoritmo Facebook´s Prophet 3.7 Red Neuronal Elman 3.8 Red Neuronal Elman con Expanding window 3.9 Red neuronal Jordan 3.10 R Markdown 3.11 Including Plots", " 3 MODELADO 3.1 Modelo de Holt Winters La metodología de Holt-Winters, también conocida como suavizamiento exponencial triple, es una técnica ampliamente utilizada en el análisis de series temporales para realizar pronósticos que presentan patrones de tendencia y estacionalidad. Esta metodología extiende el suavizamiento exponencial simple incorporando componentes adicionales que permiten capturar dinámicamente la evolución de la tendencia y la estacionalidad a lo largo del tiempo. Holt-Winters se presenta en dos variantes principales: aditiva y multiplicativa, dependiendo de la naturaleza del componente estacional. Es particularmente útil en contextos donde los datos muestran fluctuaciones regulares en intervalos específicos (como días, semanas o meses), y permite generar predicciones a corto y mediano plazo con un alto grado de precisión. Su implementación práctica ha demostrado ser eficaz en áreas como la economía, la meteorología, la gestión de inventarios y el consumo de recursos, como agua o energía(Hurtado Garzón 2013). Teniendo en cuenta la fase de preprocesamiento, se observa que la serie transformada por el logaritmo (es decir no se uso la serie diferenciada que es estacionaria) presenta una estacionalidad visible, así como una tendencia definida, caracterizada por un comportamiento que decrece, se estabiliza y vuelve a decrecer. Esto indica que cumple con los criterios visuales necesarios para aplicar la metodología en cuestión. Además, el patrón estacional parece ser claro y repetitivo, lo cual sugiere la presencia de una estacionalidad aditiva. No obstante, al implementar el modelo, es importante considerar los residuos, ya que se identifican picos que podrían estar asociados a eventos atípicos o posibles errores de medición. Cabe resaltar que esta metodología no requiere que la serie sea estacionaria. En cambio, se enfoca en identificar una tendencia y una estacionalidad bien definidas, ya que el pronóstico se basa en estos dos componentes junto con la media de la serie. A continuación, se procede a aplicar el método de Holt Winter a los precios de cierre diarios del Bitcoin, dentro de la aplicación de este modelo se asume una estacionalidad aditiva. #install.packages(&quot;quantmod&quot;) library(quantmod) ## Loading required package: xts ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: TTR ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo library(zoo) library(forecast) library(ggplot2) `{r cargar-librerias, message=FALSE, warning=FALSE} library(quantmod) # &lt;- Esta línea es clave library(zoo) # (si vas a usar as.zoo) # Descargar datos de Yahoo Finance getSymbols(&quot;BTC-USD&quot;, src = &quot;yahoo&quot;, from = &quot;2018-01-01&quot;, to = &quot;2025-04-27&quot;,#Sys.Date(), periodicity = &quot;daily&quot;) ## [1] &quot;BTC-USD&quot; # Convertir el objeto descargado a &#39;zoo&#39; btc_zoo &lt;- as.zoo(`BTC-USD`) # Ver las primeras filas tail(btc_zoo) ## BTC-USD.Open BTC-USD.High BTC-USD.Low BTC-USD.Close BTC-USD.Volume ## 2025-04-22 87521.88 93817.38 87084.53 93441.89 55899038456 ## 2025-04-23 93427.59 94535.73 91962.96 93699.11 41719568821 ## 2025-04-24 93692.40 94016.20 91696.71 93943.80 31483175315 ## 2025-04-25 93954.25 95768.39 92898.59 94720.50 40915232364 ## 2025-04-26 94714.65 95251.36 93927.25 94646.93 17612825123 ## 2025-04-27 94660.91 95301.20 93665.40 93754.84 18090367764 ## BTC-USD.Adjusted ## 2025-04-22 93441.89 ## 2025-04-23 93699.11 ## 2025-04-24 93943.80 ## 2025-04-25 94720.50 ## 2025-04-26 94646.93 ## 2025-04-27 93754.84 library(zoo) btc_close &lt;- as.zoo(btc_zoo$`BTC-USD.Close`) btc_ts &lt;- ts(coredata(btc_close), frequency = 365, start = c(2018, 1)) se procede a realizar la división de datos de entrenamiento y de test # Porcentaje de división train_ratio &lt;- 0.9 n &lt;- length(btc_ts) n_train &lt;- floor(n * train_ratio) n_test &lt;- n - n_train # Crear subconjuntos de entrenamiento y prueba btc_train &lt;- window(btc_ts, end = time(btc_ts)[n_train]) btc_test &lt;- window(btc_ts, start = time(btc_ts)[n_train + 1]) a continuación se procede a entrenar el modelo. modelo_hw &lt;- HoltWinters(btc_train) summary(modelo_hw) ## Length Class Mode ## fitted 8164 mts numeric ## x 2406 ts numeric ## alpha 1 -none- numeric ## beta 1 -none- numeric ## gamma 1 -none- numeric ## coefficients 367 -none- numeric ## seasonal 1 -none- character ## SSE 1 -none- numeric ## call 2 -none- call Como siguiente paso se procede a realizar la predicción sobre el horizonte de prueba # Pronóstico sobre los datos de test forecast_hw &lt;- forecast(modelo_hw, h = n_test) autoplot(forecast_hw) + ggtitle(&quot;Pronóstico de BTC/USD con Holt-Winters&quot;) + ylab(&quot;Precio de Cierre&quot;) + xlab(&quot;Fecha&quot;) # Graficar plot(forecast_hw, main = &quot;Holt-Winters - Predicción vs Real&quot;) lines(btc_test, col = &quot;red&quot;, lwd = 2) # Observado en rojo legend(&quot;topleft&quot;, legend = c(&quot;Predicción&quot;, &quot;Real&quot;), col = c(&quot;blue&quot;, &quot;red&quot;), lty = 1) library(Metrics) ## ## Attaching package: &#39;Metrics&#39; ## The following object is masked from &#39;package:forecast&#39;: ## ## accuracy # Extraer valores predicted &lt;- forecast_hw$mean actual &lt;- btc_test # Métricas rmse_val &lt;- rmse(actual, predicted) mae_val &lt;- mae(actual, predicted) mape_val &lt;- mape(actual, predicted) cat(&quot;📊 RMSE:&quot;, rmse_val, &quot;\\n&quot;) ## 📊 RMSE: 27326.58 cat(&quot;📊 MAE :&quot;, mae_val, &quot;\\n&quot;) ## 📊 MAE : 22457.13 cat(&quot;📊 MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) ## 📊 MAPE: 24.56 % 3.2 EXpanding windows Holt winter expanding_holt_winters &lt;- function(serie_ts, initial_train_ratio = 0.8) { library(forecast) library(Metrics) n &lt;- length(serie_ts) n_train &lt;- floor(n * initial_train_ratio) errores &lt;- c() reales &lt;- c() predichos &lt;- c() for (i in n_train:(n - 1)) { # Expanding window hasta el tiempo i ts_train &lt;- window(serie_ts, end = time(serie_ts)[i]) # Ajustar modelo Holt-Winters modelo &lt;- HoltWinters(ts_train) # Predecir 1 paso adelante pred &lt;- forecast(modelo, h = 1)$mean[1] # Valor real del siguiente punto real &lt;- serie_ts[i + 1] # Guardar valores errores &lt;- c(errores, real - pred) reales &lt;- c(reales, real) predichos &lt;- c(predichos, pred) } # Evaluar métricas rmse_val &lt;- rmse(reales, predichos) mae_val &lt;- mae(reales, predichos) mape_val &lt;- mape(reales, predichos) cat(&quot;📊 Expanding Window - Holt-Winters\\n&quot;) cat(&quot;RMSE:&quot;, round(rmse_val, 2), &quot;\\n&quot;) cat(&quot;MAE :&quot;, round(mae_val, 2), &quot;\\n&quot;) cat(&quot;MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) # Gráfico comparativo ts_reales &lt;- ts(reales, start = time(serie_ts)[n_train + 1], frequency = frequency(serie_ts)) ts_predichos &lt;- ts(predichos, start = time(serie_ts)[n_train + 1], frequency = frequency(serie_ts)) plot(ts_reales, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, main = &quot;Expanding Window: Real vs Predicción (Holt-Winters)&quot;, ylab = &quot;Precio BTC&quot;) lines(ts_predichos, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicción&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1) } resultado_hw&lt;-expanding_holt_winters(btc_ts, initial_train_ratio = 0.9) ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## Warning in HoltWinters(ts_train): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH ## 📊 Expanding Window - Holt-Winters ## RMSE: 2255.36 ## MAE : 1608.23 ## MAPE: 1.98 % 3.3 Metodología Box-Jenkins La metodología Box-Jenkins es un enfoque sistemático que permite identificar, estimar y validar modelos ARMA o ARIMA que se ajusten adecuadamente a una serie de tiempo. Esta metodología consta de cuatro etapas principales: Identificación del modelo En esta etapa se analiza si la serie es estacionaria. Si no lo es, se aplican transformaciones (como la diferenciación) para lograr la estacionariedad. A continuación, se identifican los posibles valores de los parámetros del modelo ARIMA(p, d, q), con base en el análisis gráfico y estadístico. Actividades comunes: Análisis gráfico: para detectar tendencia, estacionalidad o cambios en la media. Prueba de estacionariedad: como la prueba de Dickey-Fuller, que evalúa si la serie tiene raíz unitaria. Diferenciación: si la serie no es estacionaria, se aplica una o más veces para lograr la estacionariedad y determinar el parámetro d. Revisión de ACF y PACF: ACF (autocorrelación): ayuda a identificar el orden q (media móvil). PACF (autocorrelación parcial): permite sugerir el orden p (autorregresivo). Estimación de parámetros Una vez identificado el modelo, se ajusta a los datos para estimar sus parámetros. Actividades: Estimar los coeficientes mediante métodos como máxima verosimilitud. Evaluar la significancia estadística de los parámetros. Comparar modelos alternativos utilizando criterios como: AIC (Criterio de Información de Akaike) BIC (Criterio de Información Bayesiano) RMSE (Raíz del error cuadrático medio) Verificación del modelo Se valida que los residuos del modelo se comporten como ruido blanco, es decir, que no presenten autocorrelación y tengan media cero y varianza constante. Actividades: Analizar los residuos en el tiempo. Revisar los gráficos de ACF y PACF de los residuos. Verificar la normalidad mediante histogramas o pruebas como Shapiro-Wilk. Verificar independencia mediante pruebas como Ljung-Box. Si los supuestos no se cumplen, se debe reconsiderar el modelo y repetir las etapas anteriores. Pronóstico Una vez validado el modelo, se procede a generar pronósticos a corto, mediano o largo plazo. Actividades: Generar predicciones con intervalos de confianza. Comparar los pronósticos con datos reales (si están disponibles). Evaluar la precisión del modelo predictivo. Cabe resaltar que actualmente se dispone de la librería forecast en R, la cual incluye la función auto.arima, que permite seleccionar automáticamente los parámetros del modelo ARIMA de forma eficiente. Este procedimiento se basa en criterios estadísticos como AIC o BIC para identificar la combinación óptima de parámetros (p,d,q). Gracias a esta automatización, se simplifican varios pasos tradicionales del proceso de modelado, como la inspección visual de los gráficos ACF y PACF, la identificación manual del grado de diferenciación d, y la evaluación de múltiples combinaciones de parámetros para encontrar el mejor modelo. Por tanto, en esta etapa nos enfocaremos únicamente en la validación de los supuestos del modelo sobre los residuos y en la evaluación del desempeño de los pronósticos (Hurtado Garzón 2013). 3.4 Modelo Arima Los modelos autorregresivos integrados de media móvil (ARIMA, por sus siglas en inglés: AutoRegressive Integrated Moving Average) combinan tres componentes: AR (Autorregresivo): la serie se explica por sus propios valores pasados. I (Integrado): se aplican diferenciaciones a la serie para hacerla estacionaria. MA (Media móvil): se modela el error como una combinación lineal de errores pasados. Un modelo ARIMA se denota como ARIMA(p, d, q), donde: p: número de términos autorregresivos (AR). d: número de diferenciaciones necesarias para hacer la serie estacionaria. q: número de términos de medias móviles (MA). Estos modelos permiten describir y pronosticar el comportamiento de una serie de tiempo a partir de sus valores y errores pasados (Hurtado Garzón 2013). 3.4.1 Transformación serie de tiempo a estacionaria. library(tseries) adf.test(btc_ts,, alternative = c(&quot;stationary&quot;, &quot;explosive&quot;)) ## ## Augmented Dickey-Fuller Test ## ## data: btc_ts ## Dickey-Fuller = -1.9006, Lag order = 13, p-value = 0.6204 ## alternative hypothesis: stationary De acuerdo a la prueba Dickey Fuller se concluye que la serie de tiempo no es estacionaria dado que el Valor P esta por encima 0.05 , tal como se esperaba de acuerdo a su naturaleza de mercado financiero. Por lo tanto a continuación se procede a realizar la diferenciación de la serie de tiempo. ndiffs(btc_ts) ## [1] 1 ## [1] 1 #nos indica que 1 así que diferenciamos una vez y la llamamos dif.Indice.ts dif.btc.ts&lt;-diff(btc_ts) #la graficamos plot(dif.btc.ts, main=&quot; &quot;, ylab=&quot;valor&quot;, col=&quot;deepskyblue&quot;, xlab=&quot;Años&quot;) title(main=&quot;DIF Precios diarios BTC&quot;) Ahora se procede a confirmar nuevamente con la prueba Dickey Fuller que la serie diferenciada si sea estacionaria. adf.test(dif.btc.ts,, alternative = c(&quot;stationary&quot;, &quot;explosive&quot;)) ## Warning in adf.test(dif.btc.ts, , alternative = c(&quot;stationary&quot;, &quot;explosive&quot;)): ## p-value smaller than printed p-value ## ## Augmented Dickey-Fuller Test ## ## data: dif.btc.ts ## Dickey-Fuller = -12.708, Lag order = 13, p-value = 0.01 ## alternative hypothesis: stationary De acuerdo al resultado de la prueba, se puede afirmar que la serie diferenciada es estacionaria 3.4.2 Funciones de ACF y PACT Continuando con la metodología Box-Jenkins, ahora se define y genera las funciones ACF y PACT En análisis de series de tiempo, la ACF (Función de Autocorrelación) y la PACF (Función de Autocorrelación Parcial) son herramientas visuales que ayudan a identificar la estructura de dependencia dentro de una serie temporal. La ACF muestra la correlación de una serie consigo misma a diferentes rezagos, mientras que la PACF controla la correlación de los rezagos anteriores al evaluar la correlación en un rezago específico. ACF (Función de Autocorrelación) La ACF grafica la correlación entre una variable y sus valores rezagados en diferentes rezagos (diferencia de tiempo entre una observación y otra). Ayuda a identificar patrones como estacionalidad, tendencias y persistencia en la serie. Se utiliza para determinar el orden del modelo AR (Autorregresivo) y MA (Promedio Móvil). PACF (Función de Autocorrelación Parcial) La PACF muestra la correlación entre una variable y sus valores rezagados, después de haber eliminado el efecto de los rezagos intermedios. Ayuda a identificar el rezago exacto después del cual las autocorrelaciones cesan, lo cual es crucial para determinar el orden del modelo AR. Se utiliza para identificar la presencia de patrones estacionales en la serie. Diferencias clave: La ACF considera todas las correlaciones, mientras que la PACF solo considera las correlaciones directas, eliminando las indirectas. La ACF es útil para identificar la estructura general de correlación, mientras que la PACF ayuda a identificar la estructura de dependencia más precisa. Interpretación: Un corte abrupto en el gráfico ACF en un rezago específico sugiere que un modelo de series temporales con ese número de rezagos podría ser apropiado. Un gráfico ACF que decae lentamente puede indicar una tendencia en los datos. Un corte brusco en el gráfico PACF puede indicar la presencia de estacionalidad. ACF&lt;-acf(dif.btc.ts) PACF&lt;-pacf(dif.btc.ts) A continuación se procede a dividir la serie de tiempo diferenciada para la fasde de entrenamiento y de test # Parámetros de división train_ratio &lt;- 0.9 n &lt;- length(dif.btc.ts) n_train &lt;- floor(n * train_ratio) n_test &lt;- n - n_train # Dividir en train y test dif_train &lt;- window(dif.btc.ts, end = time(dif.btc.ts)[n_train]) dif_test &lt;- window(dif.btc.ts, start = time(dif.btc.ts)[n_train + 1]) 3.4.3 Modelado Autoarima modelo &lt;- auto.arima(dif_train) modelo ## Series: dif_train ## ARIMA(1,0,0) with zero mean ## ## Coefficients: ## ar1 ## -0.0533 ## s.e. 0.0204 ## ## sigma^2 = 1100170: log likelihood = -20140 ## AIC=40283.99 AICc=40284 BIC=40295.56 pred_arima &lt;- forecast(modelo, h = n_test) d &lt;- ndiffs(btc_ts) last_value &lt;- btc_ts[n_train + d] # valor original antes del primer test predicted &lt;- cumsum(pred_arima$mean) + last_value # Valores reales correspondientes a la serie original actual &lt;- window(btc_ts, start = time(btc_ts)[n_train + d + 1]) summary(actual) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 53949 64326 84623 81836 96457 106146 summary(predicted) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 61614 61615 61615 61615 61615 61625 rmse_val &lt;- rmse(actual, predicted) mae_val &lt;- mae(actual, predicted) mape_val &lt;- mape(actual, predicted) cat(&quot;📊 RMSE:&quot;, rmse_val, &quot;\\n&quot;) ## 📊 RMSE: 25727.04 cat(&quot;📊 MAE :&quot;, mae_val, &quot;\\n&quot;) ## 📊 MAE : 21253.18 cat(&quot;📊 MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) ## 📊 MAPE: 23.31 % predicted_ts &lt;- ts(predicted, start = start(actual), frequency = frequency(btc_ts)) plot(actual, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, main = &quot;Predicción vs Real (ARIMA)&quot;, ylab = &quot;Precio&quot;, ylim = range(c(actual, predicted_ts)) * c(0.9, 1.05)) # más margen abajo lines(predicted_ts, col = &quot;blue&quot;, lwd = 2) 3.5 Expanding window Arima expanding_arima_forecast &lt;- function(serie_ts, initial_train_ratio = 0.9) { library(forecast) library(Metrics) n &lt;- length(serie_ts) n_train &lt;- floor(n * initial_train_ratio) reales &lt;- c() predichos &lt;- c() for (i in n_train:(n - 1)) { # 1. Ventana de entrenamiento hasta el tiempo i ts_train &lt;- window(serie_ts, end = time(serie_ts)[i]) # 2. Ajustar modelo ARIMA automáticamente modelo &lt;- auto.arima(ts_train) # 3. Predecir un paso adelante pred &lt;- forecast(modelo, h = 1)$mean[1] # 4. Obtener valor real siguiente (para evaluación) real &lt;- serie_ts[i + 1] # 5. Guardar resultados reales &lt;- c(reales, real) predichos &lt;- c(predichos, pred) } # Convertir a ts para graficar alineado ts_reales &lt;- ts(reales, start = time(serie_ts)[n_train + 1], frequency = frequency(serie_ts)) ts_predichos &lt;- ts(predichos, start = time(serie_ts)[n_train + 1], frequency = frequency(serie_ts)) # Evaluar métricas rmse_val &lt;- rmse(ts_reales, ts_predichos) mae_val &lt;- mae(ts_reales, ts_predichos) mape_val &lt;- mape(ts_reales, ts_predichos) cat(&quot;📊 Expanding Window - ARIMA\\n&quot;) cat(&quot;RMSE:&quot;, round(rmse_val, 2), &quot;\\n&quot;) cat(&quot;MAE :&quot;, round(mae_val, 2), &quot;\\n&quot;) cat(&quot;MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) # Gráfico plot(ts_reales, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, main = &quot;Expanding Window: Real vs Predicción (ARIMA)&quot;, ylab = &quot;Precio BTC&quot;) lines(ts_predichos, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicción&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1) return(list(real = ts_reales, pred = ts_predichos, rmse = rmse_val, mae = mae_val, mape = mape_val)) } #resultado_arima &lt;- expanding_arima_forecast(btc_ts, initial_train_ratio = 0.9) 3.6 Regresión de una serie de tiempo y Algoritmo Facebook´s Prophet 3.6.1 Regresión de una serie El proceso de transformar una serie en una regresión consiste en usar sus valores pasados(lags) para predecir valores futuros, esto se logra mediante la creación de variables yt−1yt−1, yt−2yt−2, en general yt−kyt−k para algun k entero y un tiempo t de manera que lo valores ytyt se puedan estimar mediante el modelo: yt=β0+β1yt−1+…+βkyt−k+ϵt esta es la forma de una regresión lineal autoregresiva AR(p)(Hamilton 1994).Ademas de esta forma se pueden agregar un conjunto de variables externas XtXt, de forma que el modelo se convierte en:yt=β0+β1yt−1+…+βkyt−k+βk+1Xt+ϵtyt=β0+β1yt−1+…+βkyt−k+βk+1Xt+ϵt denominado modelo ARX (Ljung 1999) # 1. Crear variable de tiempo tiempo &lt;- 1:length(btc_ts) df_lm &lt;- data.frame( tiempo = tiempo, precio = as.numeric(btc_ts) ) # 2. Particionar por proporción train_ratio &lt;- 0.8 n &lt;- nrow(df_lm) n_train &lt;- floor(train_ratio * n) # Conjuntos de entrenamiento y prueba train_df &lt;- df_lm[1:n_train, ] test_df &lt;- df_lm[(n_train + 1):n, ] modelo_lm &lt;- lm(precio ~ tiempo, data = train_df) summary(modelo_lm) ## ## Call: ## lm(formula = precio ~ tiempo, data = train_df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16646 -8470 -5232 5103 41008 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4677.2955 550.0311 8.504 &lt;2e-16 *** ## tiempo 15.5408 0.4452 34.905 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 12710 on 2137 degrees of freedom ## Multiple R-squared: 0.3631, Adjusted R-squared: 0.3628 ## F-statistic: 1218 on 1 and 2137 DF, p-value: &lt; 2.2e-16 pred_test &lt;- predict(modelo_lm, newdata = test_df) actual_test &lt;- test_df$precio rmse_val &lt;- rmse(actual_test, pred_test) mae_val &lt;- mae(actual_test, pred_test) mape_val &lt;- mape(actual_test, pred_test) cat(&quot;📊 RMSE:&quot;, round(rmse_val, 2), &quot;\\n&quot;) ## 📊 RMSE: 31857.51 cat(&quot;📊 MAE :&quot;, round(mae_val, 2), &quot;\\n&quot;) ## 📊 MAE : 27069.4 cat(&quot;📊 MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) ## 📊 MAPE: 35.12 % plot(test_df$tiempo, actual_test, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, main = &quot;Regresión Lineal: Predicción vs Real&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precio BTC&quot;) lines(test_df$tiempo, pred_test, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicción&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1, lwd = 2) ## Expanding Window Arima expanding_linear_forecast &lt;- function(serie_ts, initial_train_ratio = 0.9) { library(Metrics) n &lt;- length(serie_ts) n_train &lt;- floor(n * initial_train_ratio) reales &lt;- c() predichos &lt;- c() for (i in n_train:(n - 1)) { # Construir datos de entrenamiento hasta el tiempo i ts_train &lt;- serie_ts[1:i] tiempo_train &lt;- 1:i df_train &lt;- data.frame( tiempo = tiempo_train, precio = as.numeric(ts_train) ) # Ajustar modelo lineal modelo &lt;- lm(precio ~ tiempo, data = df_train) # Predecir el siguiente punto (tiempo i+1) nuevo &lt;- data.frame(tiempo = i + 1) pred &lt;- predict(modelo, newdata = nuevo) # Valor real en t = i + 1 real &lt;- as.numeric(serie_ts[i + 1]) # Guardar resultados reales &lt;- c(reales, real) predichos &lt;- c(predichos, pred) } # Convertir a ts para alinear ts_reales &lt;- ts(reales, start = time(serie_ts)[n_train + 1], frequency = frequency(serie_ts)) ts_predichos &lt;- ts(predichos, start = time(serie_ts)[n_train + 1], frequency = frequency(serie_ts)) # Evaluar métricas rmse_val &lt;- rmse(ts_reales, ts_predichos) mae_val &lt;- mae(ts_reales, ts_predichos) mape_val &lt;- mape(ts_reales, ts_predichos) cat(&quot;📊 Expanding Window - Regresión Lineal\\n&quot;) cat(&quot;RMSE:&quot;, round(rmse_val, 2), &quot;\\n&quot;) cat(&quot;MAE :&quot;, round(mae_val, 2), &quot;\\n&quot;) cat(&quot;MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) # Gráfico plot(ts_reales, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, main = &quot;Expanding Window: Real vs Predicción (Regresión Lineal)&quot;, ylab = &quot;Precio BTC&quot;) lines(ts_predichos, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicción&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1) return(list(real = ts_reales, pred = ts_predichos, rmse = rmse_val, mae = mae_val, mape = mape_val)) } resultado_lm &lt;- expanding_linear_forecast(btc_ts, initial_train_ratio = 0.9) ## 📊 Expanding Window - Regresión Lineal ## RMSE: 28586.75 ## MAE : 25435.98 ## MAPE: 29.17 % 3.6.2 Algoritmo Facebook´s Prophet Prophet es un algoritmo desarrollado por el equipo de investigación de facebook para el pronostico de series de tiempo, su finalidad es la robustez frente a datos faltantes, cambios en la tendencia y múltiples estacionalidades. El modelo Prophet no es una regresión como tal, mas bien es una descomposición de forma aditiva, ya que se asume una descomposición de la serie de la siguiente forma: y(t)=g(t)+s(t)+h(t)+ϵty(t)=g(t)+s(t)+h(t)+ϵt donde: g(t):tendencia s(t):estacionalidad g(t):efecto de dias festivos ϵt:error(ruido blanco) dado que este metodo solo busca pronosticar valores futuros, no es necesario validar supuestos de normalidad en los errores, sin embargo si se debe verificar como una buena practica, que estos no estén correlacionados y que tengan media cero y varianza constante(Facebook Core Data Science Team 2023). library(prophet) ## Loading required package: Rcpp ## Loading required package: rlang ## ## Attaching package: &#39;rlang&#39; ## The following object is masked from &#39;package:Metrics&#39;: ## ## ll start_date &lt;- as.Date(&quot;2018-01-01&quot;) btc_df &lt;- data.frame( ds = seq(start_date, by = &quot;day&quot;, length.out = length(btc_ts)), y = as.numeric(btc_ts) ) n &lt;- nrow(btc_df) n_train &lt;- floor(n * 0.8) df_train &lt;- btc_df[1:n_train, ] df_test &lt;- btc_df[(n_train + 1):n, ] modelo &lt;- prophet(df_train) ## Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this. # 4. Crear dataframe futuro para predecir el mismo horizonte de test future &lt;- make_future_dataframe(modelo, periods = n - n_train) # 5. Predecir forecast &lt;- predict(modelo, future) # 6. Extraer solo predicciones del período de prueba pred_test &lt;- forecast[(n_train + 1):n, ] rmse_val &lt;- rmse(df_test$y, pred_test$yhat) mae_val &lt;- mae(df_test$y, pred_test$yhat) mape_val &lt;- mape(df_test$y, pred_test$yhat) cat(&quot;📊 Prophet con división 80/20:\\n&quot;) ## 📊 Prophet con división 80/20: cat(&quot;RMSE:&quot;, round(rmse_val, 2), &quot;\\n&quot;) ## RMSE: 33526.99 cat(&quot;MAE :&quot;, round(mae_val, 2), &quot;\\n&quot;) ## MAE : 29892.62 cat(&quot;MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) ## MAPE: 40.53 % # 8. Gráfico plot(df_test$ds, df_test$y, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, main = &quot;Predicción Prophet vs Real (80/20)&quot;, ylab = &quot;Precio BTC&quot;, xlab = &quot;Fecha&quot;) lines(pred_test$ds, pred_test$yhat, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicción&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1) ## Expading Window Prophet expanding_prophet_forecast &lt;- function(btc_ts, initial_train_ratio = 0.9) { library(prophet) library(Metrics) # 1. Preparar datos con fecha y valor btc_df &lt;- data.frame( ds = seq.Date(from = as.Date(&quot;2018-01-01&quot;), by = &quot;day&quot;, length.out = length(btc_ts)), y = as.numeric(btc_ts) ) n &lt;- nrow(btc_df) n_train &lt;- floor(n * initial_train_ratio) reales &lt;- c() predichos &lt;- c() fechas &lt;- c() for (i in n_train:(n - 1)) { # Subconjunto hasta t = i df_train &lt;- btc_df[1:i, ] # Entrenar modelo Prophet modelo &lt;- prophet(df_train, verbose = FALSE, daily.seasonality = FALSE) # Crear data.frame para predecir t = i + 1 fecha_pred &lt;- btc_df$ds[i + 1] future &lt;- data.frame(ds = fecha_pred) # Predecir forecast &lt;- predict(modelo, future) # Guardar resultados reales &lt;- c(reales, btc_df$y[i + 1]) predichos &lt;- c(predichos, forecast$yhat[1]) fechas &lt;- c(fechas, as.character(fecha_pred)) } # Convertir a serie de tiempo ts_reales &lt;- ts(reales, start = n_train + 1, frequency = 1) ts_predichos &lt;- ts(predichos, start = n_train + 1, frequency = 1) # Métricas rmse_val &lt;- rmse(ts_reales, ts_predichos) mae_val &lt;- mae(ts_reales, ts_predichos) mape_val &lt;- mape(ts_reales, ts_predichos) cat(&quot;📊 Expanding Window - Prophet\\n&quot;) cat(&quot;RMSE:&quot;, round(rmse_val, 2), &quot;\\n&quot;) cat(&quot;MAE :&quot;, round(mae_val, 2), &quot;\\n&quot;) cat(&quot;MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) # Gráfico fechas_ts &lt;- as.Date(fechas) plot(fechas_ts, ts_reales, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, main = &quot;Expanding Window: Real vs Predicción (Prophet)&quot;, ylab = &quot;Precio BTC&quot;, xlab = &quot;Fecha&quot;) lines(fechas_ts, ts_predichos, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicción&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1) return(data.frame( fecha = fechas_ts, real = ts_reales, pred = ts_predichos )) } resultado_prophet &lt;- expanding_prophet_forecast(btc_ts, initial_train_ratio = 0.9) ## 📊 Expanding Window - Prophet ## RMSE: 11777.56 ## MAE : 10131.19 ## MAPE: 12.34 % 3.7 Red Neuronal Elman install.packages(&quot;RSNNS&quot;) ## Installing package into &#39;/cloud/lib/x86_64-pc-linux-gnu-library/4.4&#39; ## (as &#39;lib&#39; is unspecified) library(RSNNS) # Normalizar serie btc_norm &lt;- (btc_ts - min(btc_ts)) / (max(btc_ts) - min(btc_ts)) # Parámetros n_lags &lt;- 7 n &lt;- length(btc_norm) n_train &lt;- floor(n * 0.9) # Crear matriz de entrada y salida crear_dataset &lt;- function(serie, n_lags) { X &lt;- embed(serie, n_lags + 1) y &lt;- X[, 1] X &lt;- X[, -1] return(list(X = X, y = y)) } datos &lt;- crear_dataset(btc_norm, n_lags) X &lt;- datos$X y &lt;- datos$y # División train/test X_train &lt;- X[1:(n_train - n_lags), ] y_train &lt;- y[1:(n_train - n_lags)] X_test &lt;- X[(n_train - n_lags + 1):(n - n_lags), ] y_test &lt;- y[(n_train - n_lags + 1):(n - n_lags)] # Ajustar red Elman modelo_elman &lt;- elman(X_train, y_train, size = 10, learnFuncParams = c(0.1), maxit = 100, linOut = TRUE) # Predicción pred_norm &lt;- predict(modelo_elman, X_test) # Desnormalizar min_y &lt;- min(btc_ts) max_y &lt;- max(btc_ts) pred &lt;- pred_norm * (max_y - min_y) + min_y real &lt;- y_test * (max_y - min_y) + min_y library(Metrics) cat(&quot;📊 Elman Neural Net:\\n&quot;) ## 📊 Elman Neural Net: cat(&quot;RMSE:&quot;, round(rmse(real, pred), 2), &quot;\\n&quot;) ## RMSE: 15327.92 cat(&quot;MAE :&quot;, round(mae(real, pred), 2), &quot;\\n&quot;) ## MAE : 12516.27 cat(&quot;MAPE:&quot;, round(mape(real, pred) * 100, 2), &quot;%\\n&quot;) ## MAPE: 13.7 % # Gráfico plot(real, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, ylab = &quot;Precio BTC&quot;, main = &quot;Red Elman&quot;) lines(pred, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicho&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1) 3.8 Red Neuronal Elman con Expanding window expanding_elman_forecast &lt;- function(btc_ts, n_lags = 5, size = 10, initial_train_ratio = 0.8, maxit = 100) { library(RSNNS) library(Metrics) # Normalizar la serie btc_norm &lt;- (btc_ts - min(btc_ts)) / (max(btc_ts) - min(btc_ts)) min_val &lt;- min(btc_ts) max_val &lt;- max(btc_ts) # Preparar función para ventana deslizante crear_dataset &lt;- function(serie, n_lags) { X &lt;- embed(serie, n_lags + 1) y &lt;- X[, 1] X &lt;- X[, -1] return(list(X = X, y = y)) } datos &lt;- crear_dataset(btc_norm, n_lags) X_all &lt;- datos$X y_all &lt;- datos$y total &lt;- nrow(X_all) # Punto inicial para expanding window start &lt;- floor(total * initial_train_ratio) pred &lt;- c() real &lt;- c() for (i in start:(total - 1)) { X_train &lt;- X_all[1:i, ] y_train &lt;- y_all[1:i] X_next &lt;- matrix(X_all[i + 1, ], nrow = 1) # Ajustar red Elman modelo &lt;- elman(X_train, y_train, size = size, learnFuncParams = c(0.1), maxit = maxit, linOut = TRUE) pred_i &lt;- predict(modelo, X_next) pred &lt;- c(pred, pred_i) real &lt;- c(real, y_all[i + 1]) } # Desnormalizar pred_desnorm &lt;- pred * (max_val - min_val) + min_val real_desnorm &lt;- real * (max_val - min_val) + min_val # Métricas rmse_val &lt;- rmse(real_desnorm, pred_desnorm) mae_val &lt;- mae(real_desnorm, pred_desnorm) mape_val &lt;- mape(real_desnorm, pred_desnorm) cat(&quot;📊 Expanding Window - Red Elman\\n&quot;) cat(&quot;RMSE:&quot;, round(rmse_val, 2), &quot;\\n&quot;) cat(&quot;MAE :&quot;, round(mae_val, 2), &quot;\\n&quot;) cat(&quot;MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) # Gráfico plot(real_desnorm, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, ylab = &quot;Precio BTC&quot;, main = &quot;Red Elman - Expanding Window&quot;) lines(pred_desnorm, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicho&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1) return(data.frame(real = real_desnorm, pred = pred_desnorm)) } resultado_elman &lt;- expanding_elman_forecast(btc_ts, n_lags = 7, size = 10) ## 📊 Expanding Window - Red Elman ## RMSE: 2137.92 ## MAE : 1542.39 ## MAPE: 2.24 % 3.9 Red neuronal Jordan expanding_jordan_forecast &lt;- function(btc_ts, n_lags = 7, size = 10, initial_train_ratio = 0.9, maxit = 100) { library(RSNNS) library(Metrics) # 1. Normalizar serie btc_norm &lt;- (btc_ts - min(btc_ts)) / (max(btc_ts) - min(btc_ts)) min_val &lt;- min(btc_ts) max_val &lt;- max(btc_ts) # 2. Crear dataset con ventanas crear_dataset &lt;- function(serie, n_lags) { X &lt;- embed(serie, n_lags + 1) y &lt;- X[, 1] X &lt;- X[, -1] return(list(X = X, y = y)) } datos &lt;- crear_dataset(btc_norm, n_lags) X_all &lt;- datos$X y_all &lt;- datos$y total &lt;- nrow(X_all) # 3. División inicial start &lt;- floor(total * initial_train_ratio) pred &lt;- c() real &lt;- c() for (i in start:(total - 1)) { X_train &lt;- X_all[1:i, ] y_train &lt;- y_all[1:i] X_next &lt;- matrix(X_all[i + 1, ], nrow = 1) # 4. Ajustar modelo Jordan modelo &lt;- jordan(X_train, y_train, size = size, learnFuncParams = c(0.1), maxit = maxit, linOut = TRUE) pred_i &lt;- predict(modelo, X_next) pred &lt;- c(pred, pred_i) real &lt;- c(real, y_all[i + 1]) } # 5. Desnormalizar pred_desnorm &lt;- pred * (max_val - min_val) + min_val real_desnorm &lt;- real * (max_val - min_val) + min_val # 6. Métricas rmse_val &lt;- rmse(real_desnorm, pred_desnorm) mae_val &lt;- mae(real_desnorm, pred_desnorm) mape_val &lt;- mape(real_desnorm, pred_desnorm) cat(&quot;📊 Expanding Window - Red Jordan\\n&quot;) cat(&quot;RMSE:&quot;, round(rmse_val, 2), &quot;\\n&quot;) cat(&quot;MAE :&quot;, round(mae_val, 2), &quot;\\n&quot;) cat(&quot;MAPE:&quot;, round(mape_val * 100, 2), &quot;%\\n&quot;) # 7. Gráfico plot(real_desnorm, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, ylab = &quot;Precio BTC&quot;, main = &quot;Red Jordan - Expanding Window&quot;) lines(pred_desnorm, col = &quot;blue&quot;, lwd = 2) legend(&quot;topleft&quot;, legend = c(&quot;Real&quot;, &quot;Predicho&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = 1) return(data.frame(real = real_desnorm, pred = pred_desnorm)) } resultado_jordan &lt;- expanding_jordan_forecast(btc_ts, n_lags = 7, size = 10) ## 📊 Expanding Window - Red Jordan ## RMSE: 2350.64 ## MAE : 1756.91 ## MAPE: 2.16 % 3.10 R Markdown 3.11 Including Plots "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
